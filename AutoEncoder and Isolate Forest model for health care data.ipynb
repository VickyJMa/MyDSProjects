{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8ed26e",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "I saved the \"inpatientCharges.csv' file after EDA and feature engineering as a new .csv file called \"healthcare.csv\", which I will use for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12974c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('healthcare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5a3564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163065 entries, 0 to 163064\n",
      "Data columns (total 29 columns):\n",
      " #   Column                                        Non-Null Count   Dtype  \n",
      "---  ------                                        --------------   -----  \n",
      " 0   DRG                                           163065 non-null  object \n",
      " 1   Provider_Id                                   163065 non-null  int64  \n",
      " 2   Provider_Name                                 163065 non-null  object \n",
      " 3   Provider_StreetAddress                        163065 non-null  object \n",
      " 4   Provider_City                                 163065 non-null  object \n",
      " 5   Provider_State                                163065 non-null  object \n",
      " 6   Provider_Zipcode                              163065 non-null  int64  \n",
      " 7   Hospital_referral_region_desp                 163065 non-null  object \n",
      " 8   Total_Discharges                              163065 non-null  int64  \n",
      " 9   Average_Total_Payments                        163065 non-null  float64\n",
      " 10  Average_Medicare_Payment                      163065 non-null  float64\n",
      " 11  City_State                                    163065 non-null  object \n",
      " 12  City_Zip                                      163065 non-null  object \n",
      " 13  Location_Group                                163065 non-null  object \n",
      " 14  Total_Payments_Per_Discharge                  163065 non-null  float64\n",
      " 15  Medicare_Payments_Per_Discharge               163065 non-null  float64\n",
      " 16  Payment_Difference                            163065 non-null  float64\n",
      " 17  Provider_Size                                 163065 non-null  object \n",
      " 18  Ratio_AvgTotalPayments_to_Median              163065 non-null  float64\n",
      " 19  Ratio_AvgMedPayment_to_Median                 163065 non-null  float64\n",
      " 20  Ratio_TotalDischarges_to_Median               163065 non-null  float64\n",
      " 21  DRG_Median_Average_Total_Payments             163065 non-null  float64\n",
      " 22  DRG_Median_Medicare_Payment                   163065 non-null  float64\n",
      " 23  DRG_Median_Total_Discharges                   163065 non-null  float64\n",
      " 24  Ratio_AvgTotalPayments_to_Median_DRG          163065 non-null  float64\n",
      " 25  Ratio_AvgMedPayment_to_Median_DRG             163065 non-null  float64\n",
      " 26  Ratio_TotalDischarges_to_Median_DRG           163065 non-null  float64\n",
      " 27  Payment_Ratio_Deviation_from_Median_by_State  163065 non-null  float64\n",
      " 28  Payment_Ratio_Deviation_from_Median_by_DRG    163065 non-null  float64\n",
      "dtypes: float64(16), int64(3), object(10)\n",
      "memory usage: 36.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check for data type\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9fc412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN or infinity values\n",
    "if df.isnull().values.any():\n",
    "    # Fill missing values with median\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Keep 2 decimal points\n",
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67954d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features that I will use for KNN and PCA model\n",
    "selected_features = ['Total_Discharges',\n",
    "                     'Average_Total_Payments',\n",
    "                     'Average_Medicare_Payment',\n",
    "                     'Total_Payments_Per_Discharge',\n",
    "                    'Medicare_Payments_Per_Discharge',\n",
    "                    'Payment_Difference',\n",
    "                    'Ratio_AvgTotalPayments_to_Median',\n",
    "                    'Ratio_AvgMedPayment_to_Median',\n",
    "                    'Ratio_TotalDischarges_to_Median',\n",
    "                    'DRG_Median_Average_Total_Payments',\n",
    "                    'DRG_Median_Total_Discharges',\n",
    "                    'Ratio_AvgTotalPayments_to_Median_DRG',\n",
    "                    'Ratio_AvgMedPayment_to_Median_DRG',\n",
    "                    'Ratio_TotalDischarges_to_Median_DRG',\n",
    "                    'Payment_Ratio_Deviation_from_Median_by_State',\n",
    "                    'Payment_Ratio_Deviation_from_Median_by_DRG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c31713c",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "\n",
    "An autoencoder is a neural network that learns to encode input data into a more compact representation and then decode it back to the original form. By training on normal patterns, this unsupervised machine learning model can identify outliers during reconstruction, as deviations from learned patterns lead to higher errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e93bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the selected features\n",
    "X = df[selected_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split data\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff42117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Discharges</th>\n",
       "      <th>Average_Total_Payments</th>\n",
       "      <th>Average_Medicare_Payment</th>\n",
       "      <th>Total_Payments_Per_Discharge</th>\n",
       "      <th>Medicare_Payments_Per_Discharge</th>\n",
       "      <th>Payment_Difference</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median</th>\n",
       "      <th>DRG_Median_Average_Total_Payments</th>\n",
       "      <th>DRG_Median_Total_Discharges</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median_DRG</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median_DRG</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median_DRG</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_State</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_DRG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50634</th>\n",
       "      <td>24</td>\n",
       "      <td>20501.83</td>\n",
       "      <td>19789.20</td>\n",
       "      <td>854.24</td>\n",
       "      <td>824.55</td>\n",
       "      <td>-712.63</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.89</td>\n",
       "      <td>28601.24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129854</th>\n",
       "      <td>25</td>\n",
       "      <td>7553.12</td>\n",
       "      <td>5455.72</td>\n",
       "      <td>302.12</td>\n",
       "      <td>218.23</td>\n",
       "      <td>-2097.40</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>7061.00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22416</th>\n",
       "      <td>75</td>\n",
       "      <td>7929.56</td>\n",
       "      <td>7030.00</td>\n",
       "      <td>105.73</td>\n",
       "      <td>93.73</td>\n",
       "      <td>-899.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2.78</td>\n",
       "      <td>8925.30</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82322</th>\n",
       "      <td>24</td>\n",
       "      <td>3310.75</td>\n",
       "      <td>2608.58</td>\n",
       "      <td>137.95</td>\n",
       "      <td>108.69</td>\n",
       "      <td>-702.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3176.58</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86625</th>\n",
       "      <td>15</td>\n",
       "      <td>5846.80</td>\n",
       "      <td>4299.53</td>\n",
       "      <td>389.79</td>\n",
       "      <td>286.64</td>\n",
       "      <td>-1547.27</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.56</td>\n",
       "      <td>5990.31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Total_Discharges  Average_Total_Payments  Average_Medicare_Payment  \\\n",
       "50634                 24                20501.83                  19789.20   \n",
       "129854                25                 7553.12                   5455.72   \n",
       "22416                 75                 7929.56                   7030.00   \n",
       "82322                 24                 3310.75                   2608.58   \n",
       "86625                 15                 5846.80                   4299.53   \n",
       "\n",
       "        Total_Payments_Per_Discharge  Medicare_Payments_Per_Discharge  \\\n",
       "50634                         854.24                           824.55   \n",
       "129854                        302.12                           218.23   \n",
       "22416                         105.73                            93.73   \n",
       "82322                         137.95                           108.69   \n",
       "86625                         389.79                           286.64   \n",
       "\n",
       "        Payment_Difference  Ratio_AvgTotalPayments_to_Median  \\\n",
       "50634              -712.63                              2.84   \n",
       "129854            -2097.40                              1.05   \n",
       "22416              -899.56                              1.10   \n",
       "82322              -702.17                              0.46   \n",
       "86625             -1547.27                              0.81   \n",
       "\n",
       "        Ratio_AvgMedPayment_to_Median  Ratio_TotalDischarges_to_Median  \\\n",
       "50634                            3.21                             0.89   \n",
       "129854                           0.89                             0.93   \n",
       "22416                            1.14                             2.78   \n",
       "82322                            0.42                             0.89   \n",
       "86625                            0.70                             0.56   \n",
       "\n",
       "        DRG_Median_Average_Total_Payments  DRG_Median_Total_Discharges  \\\n",
       "50634                            28601.24                         24.0   \n",
       "129854                            7061.00                         27.0   \n",
       "22416                             8925.30                         73.0   \n",
       "82322                             3176.58                         25.0   \n",
       "86625                             5990.31                         16.0   \n",
       "\n",
       "        Ratio_AvgTotalPayments_to_Median_DRG  \\\n",
       "50634                                   0.72   \n",
       "129854                                  1.07   \n",
       "22416                                   0.89   \n",
       "82322                                   1.04   \n",
       "86625                                   0.98   \n",
       "\n",
       "        Ratio_AvgMedPayment_to_Median_DRG  \\\n",
       "50634                                0.75   \n",
       "129854                               0.90   \n",
       "22416                                0.86   \n",
       "82322                                1.18   \n",
       "86625                                0.81   \n",
       "\n",
       "        Ratio_TotalDischarges_to_Median_DRG  \\\n",
       "50634                                  1.00   \n",
       "129854                                 0.93   \n",
       "22416                                  1.03   \n",
       "82322                                  0.96   \n",
       "86625                                  0.94   \n",
       "\n",
       "        Payment_Ratio_Deviation_from_Median_by_State  \\\n",
       "50634                                           1.63   \n",
       "129854                                          0.12   \n",
       "22416                                           0.00   \n",
       "82322                                           0.39   \n",
       "86625                                           0.10   \n",
       "\n",
       "        Payment_Ratio_Deviation_from_Median_by_DRG  \n",
       "50634                                         0.11  \n",
       "129854                                        0.01  \n",
       "22416                                         0.06  \n",
       "82322                                         0.04  \n",
       "86625                                         0.08  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "X_train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d00039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:53:26.238064: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.auto_encoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77cf91ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                48        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632 (2.47 KB)\n",
      "Trainable params: 632 (2.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.1943 - val_loss: 1.0131\n",
      "Epoch 2/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0152 - val_loss: 0.9902\n",
      "Epoch 3/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0039 - val_loss: 0.9866\n",
      "Epoch 4/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0022 - val_loss: 0.9859\n",
      "Epoch 5/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0018 - val_loss: 0.9857\n",
      "Epoch 6/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0017 - val_loss: 0.9856\n",
      "Epoch 7/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0017 - val_loss: 0.9856\n",
      "Epoch 8/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9856\n",
      "Epoch 9/100\n",
      "3669/3669 [==============================] - 25s 7ms/step - loss: 1.0016 - val_loss: 0.9856\n",
      "Epoch 10/100\n",
      "3669/3669 [==============================] - 23s 6ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 11/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 12/100\n",
      "3669/3669 [==============================] - 19s 5ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 13/100\n",
      "3669/3669 [==============================] - 16s 4ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 14/100\n",
      "3669/3669 [==============================] - 18s 5ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 15/100\n",
      "3669/3669 [==============================] - 32s 9ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 16/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 17/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 18/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 19/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 20/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 21/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 22/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 23/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 24/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 25/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 26/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 27/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 28/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 29/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 30/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 31/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 32/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 33/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 34/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 35/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 36/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 37/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 38/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 39/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 40/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 41/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 42/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 43/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 44/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 45/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 46/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 47/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 48/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 49/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 50/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 51/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 52/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 53/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 54/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 55/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 56/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 57/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 58/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 59/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 60/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 61/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 62/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 64/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 65/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 66/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 67/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 68/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 69/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 70/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 71/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 72/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 73/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 74/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 75/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 76/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 77/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 78/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 79/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 80/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 81/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 82/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 83/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 84/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 85/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 86/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 87/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 88/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 89/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 90/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 91/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 92/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 93/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 94/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 95/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 96/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 97/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 98/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 99/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "Epoch 100/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0016 - val_loss: 0.9855\n",
      "4077/4077 [==============================] - 6s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=32, contamination=0.05, dropout_rate=0.2, epochs=100,\n",
       "      hidden_activation='relu', hidden_neurons=[2, 2], l2_regularizer=0.1,\n",
       "      loss=<function mean_squared_error at 0x7fa478199280>,\n",
       "      optimizer='adam', output_activation='sigmoid', preprocessing=True,\n",
       "      random_state=None, validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atcdr = AutoEncoder(contamination=0.05, hidden_neurons =[2, 2])\n",
    "atcdr.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea60b8a",
   "metadata": {},
   "source": [
    "- The model has one input layer, two hidden layers and one output layer. \n",
    "- The input layer is 16 because the model detects 16 input variables.\n",
    "- There are 632 parameters to be trained in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7964a500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4077/4077 [==============================] - 8s 2ms/step\n",
      "4077/4077 [==============================] - 7s 2ms/step\n",
      "1020/1020 [==============================] - 2s 2ms/step\n",
      "1020/1020 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_train_scores = atcdr.decision_function(X_train)\n",
    "y_train_pred = atcdr.predict(X_train)\n",
    "\n",
    "# Test data\n",
    "y_test_scores = atcdr.decision_function(X_test)\n",
    "y_test_pred = atcdr.predict(X_test) # outlier labels (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a6f86",
   "metadata": {},
   "source": [
    "# Determine the thershold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e39c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The threshold for the defined contamination rate: 7.846497357924179\n",
      "The training data: {0: 123929, 1: 6523}\n",
      "The training data: {0: 31025, 1: 1588}\n"
     ]
    }
   ],
   "source": [
    "# Threshold for the defined comtanimation rate\n",
    "print(\"The threshold for the defined contamination rate:\" , atcdr.threshold_)\n",
    "\n",
    "def count_stat(vector):\n",
    "    # Because it is '0' and '1', we can run a count statistic. \n",
    "    unique, counts = np.unique(vector, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "print(\"The training data:\", count_stat(y_train_pred))\n",
    "print(\"The training data:\", count_stat(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1540eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 4), dpi=80)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train_scores, bins='auto') # arguments are passed to np.histogram\n",
    "plt.title(\"Outlier score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfe7e9",
   "metadata": {},
   "source": [
    "- The threshold for the defined contamination rate is set at the approximately 7.85."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700bb6df",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d0963ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Count</th>\n",
       "      <th>Count %</th>\n",
       "      <th>Total_Discharges</th>\n",
       "      <th>Average_Total_Payments</th>\n",
       "      <th>Average_Medicare_Payment</th>\n",
       "      <th>Total_Payments_Per_Discharge</th>\n",
       "      <th>Medicare_Payments_Per_Discharge</th>\n",
       "      <th>Payment_Difference</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median</th>\n",
       "      <th>DRG_Median_Average_Total_Payments</th>\n",
       "      <th>DRG_Median_Total_Discharges</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median_DRG</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median_DRG</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median_DRG</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_State</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_DRG</th>\n",
       "      <th>Anomaly_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>123929</td>\n",
       "      <td>94.999693</td>\n",
       "      <td>40.39</td>\n",
       "      <td>8512.55</td>\n",
       "      <td>7380.15</td>\n",
       "      <td>347.08</td>\n",
       "      <td>301.27</td>\n",
       "      <td>-1132.40</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.50</td>\n",
       "      <td>8223.69</td>\n",
       "      <td>33.51</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outlier</td>\n",
       "      <td>6523</td>\n",
       "      <td>5.000307</td>\n",
       "      <td>88.51</td>\n",
       "      <td>32460.33</td>\n",
       "      <td>29723.10</td>\n",
       "      <td>1540.97</td>\n",
       "      <td>1417.60</td>\n",
       "      <td>-2737.23</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.83</td>\n",
       "      <td>3.28</td>\n",
       "      <td>28537.19</td>\n",
       "      <td>37.67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.47</td>\n",
       "      <td>1.07</td>\n",
       "      <td>11.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group   Count    Count %  Total_Discharges  Average_Total_Payments  \\\n",
       "0   Normal  123929  94.999693             40.39                 8512.55   \n",
       "1  Outlier    6523   5.000307             88.51                32460.33   \n",
       "\n",
       "   Average_Medicare_Payment  Total_Payments_Per_Discharge  \\\n",
       "0                   7380.15                        347.08   \n",
       "1                  29723.10                       1540.97   \n",
       "\n",
       "   Medicare_Payments_Per_Discharge  Payment_Difference  \\\n",
       "0                           301.27            -1132.40   \n",
       "1                          1417.60            -2737.23   \n",
       "\n",
       "   Ratio_AvgTotalPayments_to_Median  Ratio_AvgMedPayment_to_Median  \\\n",
       "0                              1.18                           1.20   \n",
       "1                              4.50                           4.83   \n",
       "\n",
       "   Ratio_TotalDischarges_to_Median  DRG_Median_Average_Total_Payments  \\\n",
       "0                             1.50                            8223.69   \n",
       "1                             3.28                           28537.19   \n",
       "\n",
       "   DRG_Median_Total_Discharges  Ratio_AvgTotalPayments_to_Median_DRG  \\\n",
       "0                        33.51                                  1.04   \n",
       "1                        37.67                                  1.22   \n",
       "\n",
       "   Ratio_AvgMedPayment_to_Median_DRG  Ratio_TotalDischarges_to_Median_DRG  \\\n",
       "0                               1.05                                 1.23   \n",
       "1                               1.20                                 1.90   \n",
       "\n",
       "   Payment_Ratio_Deviation_from_Median_by_State  \\\n",
       "0                                          0.45   \n",
       "1                                          3.47   \n",
       "\n",
       "   Payment_Ratio_Deviation_from_Median_by_DRG  Anomaly_Score  \n",
       "0                                        0.18           2.57  \n",
       "1                                        1.07          11.85  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = atcdr.threshold_ # Or other value from the above histogram\n",
    "\n",
    "def descriptive_stat_threshold(df,pred_score, threshold):\n",
    "    # Let's see how many '0's and '1's.\n",
    "    df = pd.DataFrame(df)\n",
    "    df['Anomaly_Score'] = pred_score\n",
    "    df['Group'] = np.where(df['Anomaly_Score']< threshold, 'Normal', 'Outlier')\n",
    "\n",
    "    # Now let's show the summary statistics:\n",
    "    cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n",
    "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
    "    stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n",
    "    stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n",
    "    return (stat)\n",
    "\n",
    "descriptive_stat_threshold(X_train,y_train_scores, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c7c46",
   "metadata": {},
   "source": [
    "The above table presents the characteristics of the normal and abnormal groups.\n",
    "\n",
    "- There are 123929 datapoints in \"Normal\" group which constitute 95% of the data, and there are 6523 datapoint in \"Outlier\" group which is 5% of the total data.\n",
    "- **The size of the outlier group:** The threshold for determining outliers is set at model suggested value. As a result, the size of the \"Outlier\" group is determined to be 5.00% of the total, indicating that 5% of the data points are considered outliers based on the chosen threshold.\n",
    "- **The feature statistics in each group:** All the means are consistent with the domain knowledge. In this case, the means in the outlier group are substantially larger than those of the normal group. For example, the average total payments in normal group is 8512.55 and the average total payments in outlier group is 32460.33.\n",
    "- **The average anomaly score:** The average score of the outlier group is higher than that of the normal group. (11.85>2.57)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ee2fe",
   "metadata": {},
   "source": [
    "# Aggregate to Achieve Model Stability -- Autoencoder\n",
    "\n",
    "One of the issue of neuro networks is that they are sensitive to the noises and tend to overfitting. To mitigate the model overfitting and instability, we can train multiple autoencoder models and aggregate the average score together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fe2f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to split data again because the previous model has comprimised the x_train and x_test.\n",
    "X = df[selected_features]\n",
    "X_train, X_test= train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95d2cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                48        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632 (2.47 KB)\n",
      "Trainable params: 632 (2.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.1745 - val_loss: 1.0533\n",
      "Epoch 2/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0074 - val_loss: 1.0304\n",
      "Epoch 3/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0266\n",
      "Epoch 4/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9950 - val_loss: 1.0206\n",
      "Epoch 5/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 0.9933 - val_loss: 1.0164\n",
      "Epoch 6/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9923 - val_loss: 1.0130\n",
      "Epoch 7/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9916 - val_loss: 1.0105\n",
      "Epoch 8/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9916 - val_loss: 1.0091\n",
      "Epoch 9/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9912 - val_loss: 1.0088\n",
      "Epoch 10/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9907 - val_loss: 1.0092\n",
      "Epoch 11/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9911 - val_loss: 1.0088\n",
      "Epoch 12/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9906 - val_loss: 1.0078\n",
      "Epoch 13/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9908 - val_loss: 1.0086\n",
      "Epoch 14/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9908 - val_loss: 1.0072\n",
      "Epoch 15/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9909 - val_loss: 1.0078\n",
      "Epoch 16/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9909 - val_loss: 1.0067\n",
      "Epoch 17/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9904 - val_loss: 1.0071\n",
      "Epoch 18/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9912 - val_loss: 1.0066\n",
      "Epoch 19/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9904 - val_loss: 1.0085\n",
      "Epoch 20/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9906 - val_loss: 1.0062\n",
      "Epoch 21/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9907 - val_loss: 1.0076\n",
      "Epoch 22/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9908 - val_loss: 1.0060\n",
      "Epoch 23/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9908 - val_loss: 1.0070\n",
      "Epoch 24/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9910 - val_loss: 1.0066\n",
      "Epoch 25/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9905 - val_loss: 1.0054\n",
      "Epoch 26/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9906 - val_loss: 1.0065\n",
      "Epoch 27/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9907 - val_loss: 1.0048\n",
      "Epoch 28/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9909 - val_loss: 1.0053\n",
      "Epoch 29/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9910 - val_loss: 1.0072\n",
      "Epoch 30/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9957 - val_loss: 1.0332\n",
      "Epoch 31/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9978 - val_loss: 1.0312\n",
      "Epoch 32/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9969 - val_loss: 1.0309\n",
      "Epoch 33/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9967 - val_loss: 1.0308\n",
      "Epoch 34/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 35/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 36/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 37/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 38/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 39/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 40/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 41/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 42/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 43/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 44/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 45/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 46/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 47/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 48/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 49/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 50/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 51/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 52/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 53/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 54/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 55/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 56/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 57/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 58/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 59/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 60/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 61/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 62/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 64/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 65/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 66/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 67/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 68/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 69/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 70/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 71/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 72/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 73/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 74/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 75/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 76/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 77/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 78/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 79/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 80/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 81/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 82/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 83/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 84/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 85/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 86/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 87/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 88/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 89/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 90/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 91/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 92/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 93/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 94/100\n",
      "3669/3669 [==============================] - 9s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 95/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 96/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 97/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 98/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 99/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "Epoch 100/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9966 - val_loss: 1.0308\n",
      "4077/4077 [==============================] - 8s 2ms/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                170       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                30        \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 16)                176       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 942 (3.68 KB)\n",
      "Trainable params: 942 (3.68 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.1525 - val_loss: 1.0502\n",
      "Epoch 2/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0100 - val_loss: 1.0317\n",
      "Epoch 3/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 1.0000 - val_loss: 1.0278\n",
      "Epoch 4/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9979 - val_loss: 1.0269\n",
      "Epoch 5/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9974 - val_loss: 1.0266\n",
      "Epoch 6/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9972 - val_loss: 1.0265\n",
      "Epoch 7/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 8/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 9/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 10/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 11/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 12/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 13/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 14/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 15/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 16/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 17/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 18/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 19/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 20/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 21/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 23/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 24/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 25/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 26/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 27/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 28/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 29/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 30/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 31/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 32/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 33/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 34/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 35/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 36/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 37/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 38/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 39/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 40/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 41/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 42/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 43/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 44/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 45/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 46/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 47/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 48/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 49/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 50/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 51/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 52/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 53/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 54/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 55/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 56/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 57/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 58/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 59/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 60/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 61/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 62/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 63/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 64/100\n",
      "3669/3669 [==============================] - 16s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 65/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 66/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 67/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 68/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 69/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 70/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 71/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 72/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 73/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 74/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 75/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 76/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 77/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 78/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 79/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 80/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 81/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 82/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 83/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 84/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 85/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 86/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 87/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 88/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 89/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 90/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 91/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 92/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 93/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 94/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 95/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 96/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 97/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 98/100\n",
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 99/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3669/3669 [==============================] - 10s 3ms/step - loss: 0.9971 - val_loss: 1.0265\n",
      "4077/4077 [==============================] - 8s 2ms/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 15)                255       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 15)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                160       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                30        \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 15)                165       \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 15)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 16)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1432 (5.59 KB)\n",
      "Trainable params: 1432 (5.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.1203 - val_loss: 1.0031\n",
      "Epoch 2/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0144 - val_loss: 0.9868\n",
      "Epoch 3/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0051 - val_loss: 0.9830\n",
      "Epoch 4/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.0030 - val_loss: 0.9819\n",
      "Epoch 5/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0024 - val_loss: 0.9816\n",
      "Epoch 6/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0022 - val_loss: 0.9815\n",
      "Epoch 7/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0022 - val_loss: 0.9815\n",
      "Epoch 8/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 9/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 10/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 11/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 12/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 13/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 14/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 15/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 16/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 17/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 18/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 19/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 20/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 21/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 22/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 23/100\n",
      "3669/3669 [==============================] - 16s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 24/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 25/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 26/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 27/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 28/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 29/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 30/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 31/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 32/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 33/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 34/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 35/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 36/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 37/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 38/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 39/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 40/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 41/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 42/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 43/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 44/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 45/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 46/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 47/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 48/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 49/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 50/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 51/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 52/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 53/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 55/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 56/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 57/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 58/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 59/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 60/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 61/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 62/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 63/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 64/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 65/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 66/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 67/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 68/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 69/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 70/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 71/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 72/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 73/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 74/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 75/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 76/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 77/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 78/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 79/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 80/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 81/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 82/100\n",
      "3669/3669 [==============================] - 13s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 83/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 84/100\n",
      "3669/3669 [==============================] - 11s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 85/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 86/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 87/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 88/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 89/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 90/100\n",
      "3669/3669 [==============================] - 16s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 91/100\n",
      "3669/3669 [==============================] - 16s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 92/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 93/100\n",
      "3669/3669 [==============================] - 14s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 94/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 95/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 96/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 97/100\n",
      "3669/3669 [==============================] - 15s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 98/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 99/100\n",
      "3669/3669 [==============================] - 12s 3ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "Epoch 100/100\n",
      "3669/3669 [==============================] - 13s 4ms/step - loss: 1.0021 - val_loss: 0.9814\n",
      "4077/4077 [==============================] - 9s 2ms/step\n",
      "4077/4077 [==============================] - 6s 1ms/step\n",
      "4077/4077 [==============================] - 8s 2ms/step\n",
      "4077/4077 [==============================] - 7s 2ms/step\n",
      "1020/1020 [==============================] - 2s 1ms/step\n",
      "1020/1020 [==============================] - 2s 2ms/step\n",
      "1020/1020 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.combination import aom, moa, average, maximization\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "\n",
    "# Model atcdr1 has 2 hidden layers, and each hidden layer has 2 neurons. \n",
    "atcdr1 = AutoEncoder(contamination=0.05, hidden_neurons =[2, 2])\n",
    "\n",
    "# Model atcdr2 has 3 hidden layers, and each hidden layer has 10, 2, 10 neurons respectively.\n",
    "atcdr2 = AutoEncoder(contamination=0.05, hidden_neurons =[10, 2, 10])\n",
    "\n",
    "# Model atcdr3 has 5 hidden layers, and each hidden layer has 15, 10, 2, 10 and 15 neurons respectively. \n",
    "atcdr3 = AutoEncoder(contamination=0.05, hidden_neurons =[15, 10, 2, 10, 15] )\n",
    "\n",
    "# Standardize data\n",
    "X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
    "\n",
    "# Prepare data frames so we can store the model results. There are three models.\n",
    "train_scores = np.zeros([X_train.shape[0], 3])\n",
    "test_scores = np.zeros([X_test.shape[0], 3])\n",
    "atcdr1.fit(X_train_norm)\n",
    "atcdr2.fit(X_train_norm)\n",
    "atcdr3.fit(X_train_norm)\n",
    "    \n",
    "# Store the results in each column:\n",
    "train_scores[:, 0] = atcdr1.decision_function(X_train_norm) \n",
    "train_scores[:, 1] = atcdr2.decision_function(X_train_norm) \n",
    "train_scores[:, 2] = atcdr3.decision_function(X_train_norm)\n",
    "test_scores[:, 0] = atcdr1.decision_function(X_test_norm) \n",
    "test_scores[:, 1] = atcdr2.decision_function(X_test_norm) \n",
    "test_scores[:, 2] = atcdr3.decision_function(X_test_norm)\n",
    "\n",
    "# Decision scores have to be normalized before combination\n",
    "train_scores_norm, test_scores_norm = standardizer(train_scores,test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "217d795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=80)\n",
    "# Combination by average\n",
    "y_train_by_average = average(train_scores_norm)\n",
    "y_test_by_average = average(test_scores_norm)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train_by_average, bins='auto') # arguments are passed to np.histogram\n",
    "plt.title(\"Combination by average\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb903af",
   "metadata": {},
   "source": [
    "The Histogram of the Average Prediction of the Training Data suggests the threshold around 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0afab04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Count</th>\n",
       "      <th>Count %</th>\n",
       "      <th>Total_Discharges</th>\n",
       "      <th>Average_Total_Payments</th>\n",
       "      <th>Average_Medicare_Payment</th>\n",
       "      <th>Total_Payments_Per_Discharge</th>\n",
       "      <th>Medicare_Payments_Per_Discharge</th>\n",
       "      <th>Payment_Difference</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median</th>\n",
       "      <th>DRG_Median_Average_Total_Payments</th>\n",
       "      <th>DRG_Median_Total_Discharges</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median_DRG</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median_DRG</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median_DRG</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_State</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_DRG</th>\n",
       "      <th>Anomaly_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>129031</td>\n",
       "      <td>98.91071</td>\n",
       "      <td>41.90</td>\n",
       "      <td>9313.24</td>\n",
       "      <td>8133.59</td>\n",
       "      <td>385.42</td>\n",
       "      <td>337.53</td>\n",
       "      <td>-1179.65</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.55</td>\n",
       "      <td>8958.37</td>\n",
       "      <td>33.7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outlier</td>\n",
       "      <td>1421</td>\n",
       "      <td>1.08929</td>\n",
       "      <td>124.27</td>\n",
       "      <td>45737.98</td>\n",
       "      <td>41529.38</td>\n",
       "      <td>2346.00</td>\n",
       "      <td>2133.29</td>\n",
       "      <td>-4208.60</td>\n",
       "      <td>6.34</td>\n",
       "      <td>6.74</td>\n",
       "      <td>4.60</td>\n",
       "      <td>34760.34</td>\n",
       "      <td>34.9</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.32</td>\n",
       "      <td>2.31</td>\n",
       "      <td>5.24</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group   Count   Count %  Total_Discharges  Average_Total_Payments  \\\n",
       "0   Normal  129031  98.91071             41.90                 9313.24   \n",
       "1  Outlier    1421   1.08929            124.27                45737.98   \n",
       "\n",
       "   Average_Medicare_Payment  Total_Payments_Per_Discharge  \\\n",
       "0                   8133.59                        385.42   \n",
       "1                  41529.38                       2346.00   \n",
       "\n",
       "   Medicare_Payments_Per_Discharge  Payment_Difference  \\\n",
       "0                           337.53            -1179.65   \n",
       "1                          2133.29            -4208.60   \n",
       "\n",
       "   Ratio_AvgTotalPayments_to_Median  Ratio_AvgMedPayment_to_Median  \\\n",
       "0                              1.29                           1.32   \n",
       "1                              6.34                           6.74   \n",
       "\n",
       "   Ratio_TotalDischarges_to_Median  DRG_Median_Average_Total_Payments  \\\n",
       "0                             1.55                            8958.37   \n",
       "1                             4.60                           34760.34   \n",
       "\n",
       "   DRG_Median_Total_Discharges  Ratio_AvgTotalPayments_to_Median_DRG  \\\n",
       "0                         33.7                                  1.05   \n",
       "1                         34.9                                  1.40   \n",
       "\n",
       "   Ratio_AvgMedPayment_to_Median_DRG  Ratio_TotalDischarges_to_Median_DRG  \\\n",
       "0                               1.05                                 1.25   \n",
       "1                               1.32                                 2.31   \n",
       "\n",
       "   Payment_Ratio_Deviation_from_Median_by_State  \\\n",
       "0                                          0.55   \n",
       "1                                          5.24   \n",
       "\n",
       "   Payment_Ratio_Deviation_from_Median_by_DRG  Anomaly_Score  \n",
       "0                                        0.21          -0.07  \n",
       "1                                        2.13           6.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stat_threshold(X_train,y_train_by_average, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f7a3f",
   "metadata": {},
   "source": [
    "The above table presents the characteristics of the normal and abnormal groups.\n",
    "\n",
    "- There are 129031 datapoints in \"Normal\" group which constitute 99% of the data, and there are 1421 datapoint in \"Outlier\" group which is 1% of the total data.\n",
    "- **The size of the outlier group:** The threshold for determining outliers is set at model suggested value. As a result, the size of the \"Outlier\" group is determined to be 1.10% of the total, indicating that 1% of the data points are considered outliers based on the chosen threshold.\n",
    "- **The feature statistics in each group:** All the means are consistent with the domain knowledge. In this case, the means in the outlier group are substantially larger than those of the normal group. For example, the average total payments in nomal group is 9313.24 and the average total payments in outlier group is 45737.98.\n",
    "- **The average anomaly score:** The average score of the outlier group is higher than that of the normal group. (6.00>-0.07)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6cf58",
   "metadata": {},
   "source": [
    "# Isolate Forest\n",
    "\n",
    "Isolation Forest is an unsupervised machine learning algorithm that isolates outliers in a dataset directly by constructing a random forest of decision trees. It identifies anomalies based on the observation that they require fewer steps to isolate than normal instances. This method is particularly efficient for detecting outliers in large datasets, as anomalies are isolated more readily, making the Isolation Forest model a valuable tool for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d763c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to split data again because the previous model has comprimised the x_train and x_test.\n",
    "X = df[selected_features]\n",
    "X_train, X_test= train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd76f09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='new', bootstrap=False, contamination=0.05,\n",
       "    max_features=1.0, max_samples=40, n_estimators=100, n_jobs=1,\n",
       "    random_state=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "isft = IForest(contamination=0.05, max_samples=40, behaviour='new') \n",
    "isft.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77aaddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vickyma/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/vickyma/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/vickyma/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/vickyma/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The threshold for the defined contamination rate: -4.979431411200174e-17\n",
      "The training data: {0: 123929, 1: 6523}\n",
      "The training data: {0: 31012, 1: 1601}\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_train_scores = isft.decision_function(X_train)\n",
    "y_train_pred = isft.predict(X_train)\n",
    "\n",
    "# Test data\n",
    "y_test_scores = isft.decision_function(X_test)\n",
    "y_test_pred = isft.predict(X_test) # outlier labels (0 or 1)\n",
    "\n",
    "# Threshold for the defined comtanimation rate\n",
    "print(\"The threshold for the defined contamination rate:\" , isft.threshold_)\n",
    "\n",
    "def count_stat(vector):\n",
    "    # Because it is '0' and '1', we can run a count statistic. \n",
    "    unique, counts = np.unique(vector, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "print(\"The training data:\", count_stat(y_train_pred))\n",
    "print(\"The training data:\", count_stat(y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d8e28",
   "metadata": {},
   "source": [
    "- The threshold value -4.979431411200174e-17 is an extremely small number in scientific notation. It is close to zero, indicating an extremely low contamination rate. This means that the Isolation Forest model is configured to identify anomalies based on the assumption that they constitute an exceptionally small fraction of the overall dataset. The lower the contamination rate, the more sensitive the model is to outliers, as it expects them to be rare. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad49a81",
   "metadata": {},
   "source": [
    "# Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa7151a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06250622, 0.06808501, 0.0551953 , 0.05260935, 0.05135557,\n",
       "       0.05954052, 0.04740409, 0.06721964, 0.08974219, 0.07566729,\n",
       "       0.0757045 , 0.06339075, 0.04622771, 0.05964668, 0.08043639,\n",
       "       0.04526878])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isft_vi = isft.feature_importances_\n",
    "isft_vi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10554e6c",
   "metadata": {},
   "source": [
    "- Higher values indicate that the corresponding feature is considered more important by the model.\n",
    "- The sum of all values in the array is 1, as these are often normalized to represent proportions or percentages.\n",
    "- For example:\n",
    "1. The feature corresponding to the first value in the array has an importance of approximately 6.25%.\n",
    "2. The feature corresponding to the second value has an importance of approximately 6.81%, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a394ba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_pd.columns))\n",
    "print(len(isft_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86c51b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Variable importance of IForest for Outliers')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for_plot = pd.DataFrame({'x_axis': X_train_pd.columns[:16], \n",
    "                         'y_axis': isft_vi}).sort_values(by='y_axis', ascending=True)\n",
    "for_plot['y_axis'].plot.barh()\n",
    "plt.title('Variable importance of IForest for Outliers')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f02359f4",
   "metadata": {},
   "source": [
    "- 8th feature 'Ratio_TotalDischarges_to_Median' has the highest variance importance to the model.\n",
    "- 15th feature 'Payment_Ratio_Deviation_from_Median_by_DRG' has the comparatively lowest variance importance to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75a025",
   "metadata": {},
   "source": [
    "# Determine a Reasonable Threshold for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ab8ea0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train_scores, bins='auto') # arguments are passed to np.histogram\n",
    "plt.title(\"Outlier score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52560847",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "776cf86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Count</th>\n",
       "      <th>Count %</th>\n",
       "      <th>Total_Discharges</th>\n",
       "      <th>Average_Total_Payments</th>\n",
       "      <th>Average_Medicare_Payment</th>\n",
       "      <th>Total_Payments_Per_Discharge</th>\n",
       "      <th>Medicare_Payments_Per_Discharge</th>\n",
       "      <th>Payment_Difference</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median</th>\n",
       "      <th>DRG_Median_Average_Total_Payments</th>\n",
       "      <th>DRG_Median_Total_Discharges</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median_DRG</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median_DRG</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median_DRG</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_State</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_DRG</th>\n",
       "      <th>Anomaly_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>123929</td>\n",
       "      <td>94.999693</td>\n",
       "      <td>41.69</td>\n",
       "      <td>8402.54</td>\n",
       "      <td>7266.44</td>\n",
       "      <td>345.29</td>\n",
       "      <td>298.99</td>\n",
       "      <td>-1136.09</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8114.33</td>\n",
       "      <td>33.79</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outlier</td>\n",
       "      <td>6523</td>\n",
       "      <td>5.000307</td>\n",
       "      <td>63.95</td>\n",
       "      <td>34550.35</td>\n",
       "      <td>31883.31</td>\n",
       "      <td>1574.90</td>\n",
       "      <td>1460.93</td>\n",
       "      <td>-2667.04</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.18</td>\n",
       "      <td>2.37</td>\n",
       "      <td>30614.87</td>\n",
       "      <td>32.21</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group   Count    Count %  Total_Discharges  Average_Total_Payments  \\\n",
       "0   Normal  123929  94.999693             41.69                 8402.54   \n",
       "1  Outlier    6523   5.000307             63.95                34550.35   \n",
       "\n",
       "   Average_Medicare_Payment  Total_Payments_Per_Discharge  \\\n",
       "0                   7266.44                        345.29   \n",
       "1                  31883.31                       1574.90   \n",
       "\n",
       "   Medicare_Payments_Per_Discharge  Payment_Difference  \\\n",
       "0                           298.99            -1136.09   \n",
       "1                          1460.93            -2667.04   \n",
       "\n",
       "   Ratio_AvgTotalPayments_to_Median  Ratio_AvgMedPayment_to_Median  \\\n",
       "0                              1.16                           1.18   \n",
       "1                              4.79                           5.18   \n",
       "\n",
       "   Ratio_TotalDischarges_to_Median  DRG_Median_Average_Total_Payments  \\\n",
       "0                             1.54                            8114.33   \n",
       "1                             2.37                           30614.87   \n",
       "\n",
       "   DRG_Median_Total_Discharges  Ratio_AvgTotalPayments_to_Median_DRG  \\\n",
       "0                        33.79                                  1.04   \n",
       "1                        32.21                                  1.20   \n",
       "\n",
       "   Ratio_AvgMedPayment_to_Median_DRG  Ratio_TotalDischarges_to_Median_DRG  \\\n",
       "0                               1.05                                 1.24   \n",
       "1                               1.18                                 1.61   \n",
       "\n",
       "   Payment_Ratio_Deviation_from_Median_by_State  \\\n",
       "0                                          0.44   \n",
       "1                                          3.73   \n",
       "\n",
       "   Payment_Ratio_Deviation_from_Median_by_DRG  Anomaly_Score  \n",
       "0                                        0.18          -0.18  \n",
       "1                                        1.14           0.04  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = isft.threshold_ # Or other value from the above histogram\n",
    "\n",
    "def descriptive_stat_threshold(df,pred_score, threshold):\n",
    "    # Let's see how many '0's and '1's.\n",
    "    df = pd.DataFrame(df)\n",
    "    df['Anomaly_Score'] = pred_score\n",
    "    df['Group'] = np.where(df['Anomaly_Score']< threshold, 'Normal', 'Outlier')\n",
    "\n",
    "    # Now let's show the summary statistics:\n",
    "    cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n",
    "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
    "    stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n",
    "    stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n",
    "    return (stat)\n",
    "\n",
    "descriptive_stat_threshold(X_train,y_train_scores, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245b7b9",
   "metadata": {},
   "source": [
    "The above table presents the characteristics of the normal and abnormal groups.\n",
    "\n",
    "- There are 123929 datapoints in \"Normal\" group which constitute 95% of the data, and there are 6523 datapoint in \"Outlier\" group which is 5% of the total data.\n",
    "- **The size of the outlier group:** The threshold for determining outliers is set at model suggested value. As a result, the size of the \"Outlier\" group is determined to be 5.00% of the total, indicating that 5% of the data points are considered outliers based on the chosen threshold.\n",
    "- **The feature statistics in each group:** All the means are consistent with the domain knowledge. In this case, the means in the outlier group are substantially larger than those of the normal group. For example, the average total payments in nomal group is8402.54 and the average total payments in outlier group is 34550.35.\n",
    "- **The average anomaly score:** The average score of the outlier group is higher than that of the normal group. (0.45>-0.18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9488318",
   "metadata": {},
   "source": [
    "# Achieve Model Stability by Aggregating Multiple -- iForest Models\n",
    "\n",
    "Ensembling multiple iForest models enhances outlier detection by reducing model variance and improving generalization. By combining the decisions of individual models, the ensemble becomes more robust to noise, captures diverse aspects of anomalies, and provides increased sensitivity in detecting outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbbf880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to split data again because the previous model has comprimised the x_train and x_test.\n",
    "X = df[selected_features]\n",
    "X_train, X_test= train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e75807ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.combination import aom, moa, average, maximization\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.models.iforest import IForest\n",
    "\n",
    "# Standardize data\n",
    "X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
    "\n",
    "# Test a range of the number of trees\n",
    "k_list = [100, 200, 300, 400, 500]\n",
    "n_clf = len(k_list)\n",
    "# Just prepare data frames so we can store the model results\n",
    "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
    "test_scores = np.zeros([X_test.shape[0], n_clf])\n",
    "\n",
    "# Modeling\n",
    "for i in range(n_clf):\n",
    "    k = k_list[i]\n",
    "    #isft = IForest(contamination=0.05, max_samples=k) \n",
    "    isft = IForest(contamination=0.05, n_estimators=k) \n",
    "    isft.fit(X_train_norm)\n",
    "    \n",
    "    # Store the results in each column:\n",
    "    train_scores[:, i] = isft.decision_function(X_train_norm) \n",
    "    test_scores[:, i] = isft.decision_function(X_test_norm) \n",
    "# Decision scores have to be normalized before combination\n",
    "train_scores_norm, test_scores_norm = standardizer(train_scores,test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "526d05a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combination by average\n",
    "# The test_scores_norm is 500 x 10. The \"average\" function will take the average of the 10 columns. The result \"y_by_average\" is a single column: \n",
    "y_train_by_average = average(train_scores_norm)\n",
    "y_test_by_average = average(test_scores_norm)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train_by_average, bins='auto') # arguments are passed to np.histogram\n",
    "plt.title(\"Combination by average\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b0661",
   "metadata": {},
   "source": [
    "- The Histogram of the Average Prediction of the Training Data suggests the threshold around 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83114aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Count</th>\n",
       "      <th>Count %</th>\n",
       "      <th>Total_Discharges</th>\n",
       "      <th>Average_Total_Payments</th>\n",
       "      <th>Average_Medicare_Payment</th>\n",
       "      <th>Total_Payments_Per_Discharge</th>\n",
       "      <th>Medicare_Payments_Per_Discharge</th>\n",
       "      <th>Payment_Difference</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median</th>\n",
       "      <th>DRG_Median_Average_Total_Payments</th>\n",
       "      <th>DRG_Median_Total_Discharges</th>\n",
       "      <th>Ratio_AvgTotalPayments_to_Median_DRG</th>\n",
       "      <th>Ratio_AvgMedPayment_to_Median_DRG</th>\n",
       "      <th>Ratio_TotalDischarges_to_Median_DRG</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_State</th>\n",
       "      <th>Payment_Ratio_Deviation_from_Median_by_DRG</th>\n",
       "      <th>Anomaly_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>129518</td>\n",
       "      <td>99.284028</td>\n",
       "      <td>42.87</td>\n",
       "      <td>9379.36</td>\n",
       "      <td>8189.84</td>\n",
       "      <td>389.57</td>\n",
       "      <td>341.16</td>\n",
       "      <td>-1189.53</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.59</td>\n",
       "      <td>9014.00</td>\n",
       "      <td>33.79</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outlier</td>\n",
       "      <td>934</td>\n",
       "      <td>0.715972</td>\n",
       "      <td>33.43</td>\n",
       "      <td>55560.89</td>\n",
       "      <td>51142.34</td>\n",
       "      <td>2792.92</td>\n",
       "      <td>2566.35</td>\n",
       "      <td>-4418.55</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1.24</td>\n",
       "      <td>40499.12</td>\n",
       "      <td>23.35</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.32</td>\n",
       "      <td>6.56</td>\n",
       "      <td>2.84</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group   Count    Count %  Total_Discharges  Average_Total_Payments  \\\n",
       "0   Normal  129518  99.284028             42.87                 9379.36   \n",
       "1  Outlier     934   0.715972             33.43                55560.89   \n",
       "\n",
       "   Average_Medicare_Payment  Total_Payments_Per_Discharge  \\\n",
       "0                   8189.84                        389.57   \n",
       "1                  51142.34                       2792.92   \n",
       "\n",
       "   Medicare_Payments_Per_Discharge  Payment_Difference  \\\n",
       "0                           341.16            -1189.53   \n",
       "1                          2566.35            -4418.55   \n",
       "\n",
       "   Ratio_AvgTotalPayments_to_Median  Ratio_AvgMedPayment_to_Median  \\\n",
       "0                               1.3                           1.33   \n",
       "1                               7.7                           8.30   \n",
       "\n",
       "   Ratio_TotalDischarges_to_Median  DRG_Median_Average_Total_Payments  \\\n",
       "0                             1.59                            9014.00   \n",
       "1                             1.24                           40499.12   \n",
       "\n",
       "   DRG_Median_Total_Discharges  Ratio_AvgTotalPayments_to_Median_DRG  \\\n",
       "0                        33.79                                  1.05   \n",
       "1                        23.35                                  1.46   \n",
       "\n",
       "   Ratio_AvgMedPayment_to_Median_DRG  Ratio_TotalDischarges_to_Median_DRG  \\\n",
       "0                               1.05                                 1.26   \n",
       "1                               1.40                                 1.32   \n",
       "\n",
       "   Payment_Ratio_Deviation_from_Median_by_State  \\\n",
       "0                                          0.56   \n",
       "1                                          6.56   \n",
       "\n",
       "   Payment_Ratio_Deviation_from_Median_by_DRG  Anomaly_Score  \n",
       "0                                        0.21          -0.03  \n",
       "1                                        2.84           4.54  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stat_threshold(X_train,y_train_by_average, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1abd12",
   "metadata": {},
   "source": [
    "- The above table presents the characteristics of the normal and abnormal groups.\n",
    "\n",
    "- There are 129518 datapoints in \"Normal\" group which constitute 99.3% of the data, and there are 934 datapoint in \"Outlier\" group which is 0.7% of the total data.\n",
    "- **The size of the outlier group:** The threshold for determining outliers is set at model suggested value. As a result, the size of the \"Outlier\" group is determined to be 0.72% of the total, indicating that 0.72% of the data points are considered outliers based on the chosen threshold.\n",
    "- **The feature statistics in each group:** All the means are consistent with the domain knowledge. In this case, the means in the outlier group are substantially larger than those of the normal group. For example, the average total payments in nomal group is 9379.36 and the average total payments in outlier group is 55560.89.\n",
    "- **The average anomaly score:** The average score of the outlier group is higher than that of the normal group. (4.54 > -0.03)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
